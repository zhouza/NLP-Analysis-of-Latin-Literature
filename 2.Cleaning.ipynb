{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cltk\n",
    "from cltk.corpus.utils.importer import CorpusImporter\n",
    "from cltk.stem.latin.j_v import JVReplacer\n",
    "import pickle\n",
    "import re\n",
    "import unidecode\n",
    "from nltk.tokenize.punkt import PunktLanguageVars\n",
    "from cltk.stem.latin.stem import Stemmer\n",
    "from cltk.stem.lemma import LemmaReplacer\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "from pymongo import MongoClient\n",
    "import string"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Effort not shown here: had to go into several .py files under stem/lemmatize in the cltk Latin toolkit to customize/improve the algorithms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['latin_text_perseus',\n",
       " 'latin_treebank_perseus',\n",
       " 'latin_text_latin_library',\n",
       " 'phi5',\n",
       " 'phi7',\n",
       " 'latin_proper_names_cltk',\n",
       " 'latin_models_cltk',\n",
       " 'latin_pos_lemmata_cltk',\n",
       " 'latin_treebank_index_thomisticus',\n",
       " 'latin_lexica_perseus',\n",
       " 'latin_training_set_sentence_cltk',\n",
       " 'latin_word2vec_cltk',\n",
       " 'latin_text_antique_digiliblt',\n",
       " 'latin_text_corpus_grammaticorum_latinorum',\n",
       " 'latin_text_poeti_ditalia']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus_importer = CorpusImporter('latin')\n",
    "corpus_importer.list_corpora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "for corpus in corpus_importer.list_corpora:\n",
    "    try:\n",
    "        corpus_importer.import_corpus(corpus)\n",
    "    except:\n",
    "        None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['greek_software_tlgu',\n",
       " 'greek_text_perseus',\n",
       " 'phi7',\n",
       " 'tlg',\n",
       " 'greek_proper_names_cltk',\n",
       " 'greek_models_cltk',\n",
       " 'greek_treebank_perseus',\n",
       " 'greek_lexica_perseus',\n",
       " 'greek_training_set_sentence_cltk',\n",
       " 'greek_word2vec_cltk',\n",
       " 'greek_text_lacus_curtius',\n",
       " 'greek_text_first1kgreek']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus_importer = CorpusImporter('greek')\n",
    "corpus_importer.list_corpora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded 100% 163.52 MiB | 6.22 MiB/s \r"
     ]
    }
   ],
   "source": [
    "for corpus in corpus_importer.list_corpora:\n",
    "    try:\n",
    "        corpus_importer.import_corpus(corpus)\n",
    "    except:\n",
    "        None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    # remove macrons and accents\n",
    "    cleaned = unidecode.unidecode(text)\n",
    "    # convert Js to Is and Vs to Us for consistency\n",
    "    cleaned = JVReplacer().replace(cleaned)\n",
    "    # remove any non Latin characters except for punctuation\n",
    "    cleaned = re.sub(r'[\\n]',' ',cleaned.lower())\n",
    "    cleaned = re.sub(r'[^a-zA-Z\\s\\.\\!\\?:;]*','',cleaned)\n",
    "    cleaned = re.sub(r'\\b[ivxlcdm]+\\b','',cleaned)\n",
    "    \n",
    "    return cleaned.strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "def tokenizer = LineTokenizer('latin')\n",
    "\n",
    "tokenized_data = tokenizer.tokenize(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "scraped_data = pickle.load(open('pickles/scraped_data.pkl','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = MongoClient()\n",
    "db = client.latinlit\n",
    "data = db.data\n",
    "split_data = db.splitdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_doc_chunks(data):\n",
    "    ''' need to create Mongo collection splitdata first\n",
    "    '''\n",
    "    for doc in data:\n",
    "        author_name = doc['author']\n",
    "        work_name = doc['work']\n",
    "\n",
    "        split_text = re.split(r'[\\.\\?\\!:;]',clean_text(doc['text']))\n",
    "\n",
    "        sentence_counter = 0\n",
    "        text_chunk = []\n",
    "        for text in split_text:\n",
    "            split_words = text.strip().split(' ')\n",
    "            if len(split_words) >= 5:\n",
    "                text_chunk.append(text.strip())\n",
    "                sentence_counter += 1\n",
    "            if sentence_counter == 5:\n",
    "                text_chunk_str = '. '.join(text_chunk)+'.'\n",
    "                split_data.insert_one({'author':author_name, 'work':work_name, 'text':text_chunk_str})\n",
    "                text_chunk = []\n",
    "                sentence_counter = 0\n",
    "            \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_doc_chunks(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'_id': ObjectId('5b0e0fac42f3cb02d6ebe0f4'),\n",
       "  'author': 'AA VV',\n",
       "  'work': 'Epistolae Confessorum Romanorum et Carthaginensium',\n",
       "  'text': 'argumentum huius et sequentis epistolae habes istud in epistola cypriani. exempla quoque inquit epistolae celerini boni et robusti confessoris quam ad lucianum eumdem confessorem scripserit item quid lucianus ei rescripserit misi uobis ut scire tis et laborem circa omnia et diligentiam nostram et ueritatem ipsam disceretis. celerinus confessor quam sit timoratus et cautus et humilitate ac ti more sectae nostrae uerecundus. lucianus uero circa intelligentiam dominicae lectionis ut  minus peritus et circa inuidiam uerecundiae nostrae relinquendam facilitate sua molestus nam cum dominus dixerit in nomine patris et filii et spi ritus sancti gentes tingui et in baptismo peccata dimitti. hic praecepti et legis ignarus mandat pa cem dari et peccata dimitti in pauli nomine et hoc sibi dicit ab illo esse mandatum.'},\n",
       " {'_id': ObjectId('5b0e0fac42f3cb02d6ebe0f5'),\n",
       "  'author': 'AA VV',\n",
       "  'work': 'Epistolae Confessorum Romanorum et Carthaginensium',\n",
       "  'text': 'sicut in litteris eiusdem luciani ad celerinum factis animaduerte tis etc. hanc uero et sequentes epistolas ne baluzianum opus nimium discinderetur inter epistolas cypria  nicas ad tomum quartum reiectas eo tamen loci propter accuratam chronotaxim reuocauimus. uide praecedentis epistolae argumentum ex s. cypriano acceptum et notam qua alias haec epistola remittitur. libellus martyrum nomine a luciano scriptus.'},\n",
       " {'_id': ObjectId('5b0e0fac42f3cb02d6ebe0f6'),\n",
       "  'author': 'AA VV',\n",
       "  'work': 'Epistolae Confessorum Romanorum et Carthaginensium',\n",
       "  'text': 'caldonii ad cyprianum et compresbyteros cartha gini consistentes. cum lapsorum quidam noua urgente persecutione christum confessi essent atque adeo antequam in exsilium proficiscerentur pacem peterent consulit cyprianum caldonius an pax illis danda foret. moysis et maximi presbyterorum nicostrati et ru fini diaconorum et caeterorum confessorum in fide ueritatis perseuerantium ac romae consi stentium ad cyprianum. argumentum huius epistolae recitat infra epistola nouatiani nomine cleri romani scripta. quan  quam inquiunt confessorum quoque quos hic ad huc in carcerem dignitas suae confessionis inclusit et ad certamen euangelicum sua fides in confessio ne gloriosa iam semel coronauit litteras habeas conspirantes cum litteris nostris quibus seuerita tem euangelicae disciplinae protulerunt et illicitas petitiones ab ecclesiae pudore reiecerunt  so latia quae ex cyprianis litteris perceperunt romani confessores grati agnoscunt.'},\n",
       " {'_id': ObjectId('5b0e0fac42f3cb02d6ebe0f7'),\n",
       "  'author': 'AA VV',\n",
       "  'work': 'Epistolae Confessorum Romanorum et Carthaginensium',\n",
       "  'text': 'martyrium non paena sed felicitas. uoces euangelicae faces ad inflammandam fidem. in lapsorum causa cypriani sententia acceditur. fit eiusdem mentio in epistol. cypriani  eamque integram habes tomo sequenti pag.'},\n",
       " {'_id': ObjectId('5b0e0fac42f3cb02d6ebe0f8'),\n",
       "  'author': 'AA VV',\n",
       "  'work': 'Epistolae Confessorum Romanorum et Carthaginensium',\n",
       "  'text': 'presbyterorum et diaconorum romae consistentium ad cyprianum. ecclesia romana sententiam suam de lapsis cum carthaginiensis decretis consentien tem proponit  lapsis adhibita indulgentia ad euangelii normam exigitur. pacem confesso ribus concessam gratia tantum et fauoribus inniti inde constat quod lapsi ad episcopos remittantur. seditiosa pacis postulatio felicissimi factioni imputanda. caldonii cum herculano et uictore ad clerum car thaginiensem.'}]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(split_data.find({}).limit(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def root_text(text):\n",
    "    lemmatizer = LemmaReplacer('latin')\n",
    "    stemmer = Stemmer()\n",
    "    lem_text = lemmatizer.lemmatize(text,return_string=True)\n",
    "    stem_text = stemmer.stem(lem_text)\n",
    "    # remove conjugation numbers prior to running lfidf\n",
    "    cleaned_text = clean_text(stem_text)\n",
    "    return cleaned_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "root_data = db.rootdata\n",
    "\n",
    "num_docs = split_data.find().count()\n",
    "\n",
    "for n in range(0,num_docs):\n",
    "    doc = split_data.find()[n]\n",
    "    output_text = root_text(doc['text'])\n",
    "    root_data.insert_one({'author':doc['author'], 'work':doc['work'], 'text':output_text})\n",
    "    \n",
    "#texts = [root_text(doc['text']) for doc in list(split_data.find({}))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'_id': ObjectId('5b10596542f3cb0d6ba0a3a5'),\n",
       "  'text': 'argument hic et sequo epistul habe ist in epistul cypriani. exempl quoque inqu epistul celerin bon et robust confessor qui ad lucian is confessor scrib it quis lucian is rescrib mitt tu ut sci t et labor circ omn et diligent noste et uerit ipse disceretis. celerin confesso qui sum timorat et caue et humilit atque t morio sec noste uerecundus. lucian uer circ intellegent dominic lecti ut paru pere et circ inuid uerecund noste relinqu facilit su molest nam cum domin dico in nomen pate et fil et sp rit sanci ge tingu et in baptism pecc dimitto. hic praecipi et lego ignar mando p   et pecc dimitt in paulus nomen et hic sui dico ab ille edo mando.'}]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(root_data.find({},{'text':1}).limit(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'_id': ObjectId('5b0e0fac42f3cb02d6ebe0f4'),\n",
       "  'text': 'argumentum huius et sequentis epistolae habes istud in epistola cypriani. exempla quoque inquit epistolae celerini boni et robusti confessoris quam ad lucianum eumdem confessorem scripserit item quid lucianus ei rescripserit misi uobis ut scire tis et laborem circa omnia et diligentiam nostram et ueritatem ipsam disceretis. celerinus confessor quam sit timoratus et cautus et humilitate ac ti more sectae nostrae uerecundus. lucianus uero circa intelligentiam dominicae lectionis ut  minus peritus et circa inuidiam uerecundiae nostrae relinquendam facilitate sua molestus nam cum dominus dixerit in nomine patris et filii et spi ritus sancti gentes tingui et in baptismo peccata dimitti. hic praecepti et legis ignarus mandat pa cem dari et peccata dimitti in pauli nomine et hoc sibi dicit ab illo esse mandatum.'}]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(split_data.find({},{'text':1}).limit(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_data_local = list(root_data.find({}))\n",
    "indices = np.arange(len(root_data_local))\n",
    "train_indices = np.random.choice(indices,size=int(0.9*len(indices)),replace=False)\n",
    "train_data = [root_data_local[i] for i in train_indices]\n",
    "test_data = [root_data_local[i] for i in indices if i not in train_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pymongo.results.InsertManyResult at 0x7fb883225908>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "root_train = db.roottrain\n",
    "root_test = db.roottest\n",
    "root_train.insert_many(train_data)\n",
    "root_test.insert_many(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = [doc['text'] for doc in root_data_local]\n",
    "texts_train = [doc['text'] for doc in train_data]\n",
    "texts_test = [doc['text'] for doc in test_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(texts,open('pickles/texts.pkl','wb'))\n",
    "pickle.dump(texts_train,open('pickles/texts_train.pkl','wb'))\n",
    "pickle.dump(texts_test,open('pickles/texts_test.pkl','wb'))\n",
    "pickle.dump(root_data_local,open('pickles/root_data.pkl','wb'))\n",
    "pickle.dump(train_data,open('pickles/root_train.pkl','wb'))\n",
    "pickle.dump(test_data,open('pickles/root_test.pkl','wb'))\n",
    "pickle.dump(train_indices,open('pickles/train_indices.pkl','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
